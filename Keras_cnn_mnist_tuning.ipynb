{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-cnn-mnist-tuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFIVLCAHb+t1PXw7YWITuL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/George-Nyamao/Keras-cnn-mnist-tuning/blob/master/Keras_cnn_mnist_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbh5xIWOTFF-",
        "colab_type": "text"
      },
      "source": [
        "**MNIST Handwriting Using CNN and Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4JknNgAT3lt",
        "colab_type": "text"
      },
      "source": [
        "We will use Keras on the MNIST handwriting data set, using a Convolutional Neural Network that is suited for image processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTegJ3thTEdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SzowKcKVjlt",
        "colab_type": "text"
      },
      "source": [
        "Loading our raw data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alIrpYJRBE3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JleXJH0-Wbd3",
        "colab_type": "text"
      },
      "source": [
        "Tha images are of 28x28 pixels,and therefore we need to shape them as 1x28x28 or 28x28x1, where the \"1\" indicates it's a single channel since the images are in grayscal. Color images would have had a \"3\" instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuaUAjPQHuZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as k\n",
        "\n",
        "if k.image_data_format() == 'channels_first':\n",
        "    train_images = mnist_train_images.reshape(mnist_train_images.shape[0], 1, 28, 28)\n",
        "    test_images = mnist_test_images.reshape(mnist_test_images.shape[0], 1, 28, 28)\n",
        "    input_shape = (1, 28, 28)\n",
        "else:\n",
        "    train_images = mnist_train_images.reshape(mnist_train_images.shape[0], 28, 28, 1)\n",
        "    test_images = mnist_test_images.reshape(mnist_test_images.shape[0], 28, 28, 1)\n",
        "    input_shape = (28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rd17tdSYfj_",
        "colab_type": "text"
      },
      "source": [
        "We then convert them to float and scale them between 0 and 1 by dividing by 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCGdYP9pJARH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        "\n",
        "train_images /= 255\n",
        "test_images /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iovl5o4yY_xO",
        "colab_type": "text"
      },
      "source": [
        "We then convert our train and test labels to categorical in one-hot format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ5frhS3JEQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = tensorflow.keras.utils.to_categorical(mnist_train_labels, 10)\n",
        "test_labels = tensorflow.keras.utils.to_categorical(mnist_test_labels, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcw7WUAEZ2xX",
        "colab_type": "text"
      },
      "source": [
        "Print out one sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWjgU5k_JOc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "c25ec30b-cf27-44e0-de9b-3a4ddc2615c7"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_sample(num):\n",
        "    #Print the one-hot array of this sample's label \n",
        "    print(train_labels[num])  \n",
        "    #Print the label converted back to a number\n",
        "    label = train_labels[num].argmax(axis=0)\n",
        "    #Reshape the 768 values to a 28x28 image\n",
        "    image = train_images[num].reshape([28,28])\n",
        "    plt.title('Sample: %d  Label: %d' % (num, label))\n",
        "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
        "    plt.show()\n",
        "    \n",
        "display_sample(1234)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH4knIcQaPt2",
        "colab_type": "text"
      },
      "source": [
        "**Model 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9Xa9NcybKFW",
        "colab_type": "text"
      },
      "source": [
        "Our first model will have two Conv2D layers, one MaxPooling2D layer, a Flatten and then two Dense layers. We will use a batch size of 32."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGYOjMTQbACa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXecc0V7cE1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "4d521c86-9adb-4036-e833-41d3f8eec266"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7pu2PijcdS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CimiWXbocoB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "dc4acbd8-515e-4e69-e9a5-4491e6f5fa04"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    batch_size=32,\n",
        "                    epochs=10,\n",
        "                    verbose=2,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 - 7s - loss: 0.1095 - accuracy: 0.9668 - val_loss: 0.0540 - val_accuracy: 0.9823\n",
            "Epoch 2/10\n",
            "1875/1875 - 6s - loss: 0.0356 - accuracy: 0.9892 - val_loss: 0.0382 - val_accuracy: 0.9887\n",
            "Epoch 3/10\n",
            "1875/1875 - 6s - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0364 - val_accuracy: 0.9885\n",
            "Epoch 4/10\n",
            "1875/1875 - 6s - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0384 - val_accuracy: 0.9890\n",
            "Epoch 5/10\n",
            "1875/1875 - 6s - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0362 - val_accuracy: 0.9908\n",
            "Epoch 6/10\n",
            "1875/1875 - 6s - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0598 - val_accuracy: 0.9864\n",
            "Epoch 7/10\n",
            "1875/1875 - 6s - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.0472 - val_accuracy: 0.9883\n",
            "Epoch 8/10\n",
            "1875/1875 - 6s - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0381 - val_accuracy: 0.9913\n",
            "Epoch 9/10\n",
            "1875/1875 - 6s - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0684 - val_accuracy: 0.9870\n",
            "Epoch 10/10\n",
            "1875/1875 - 6s - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0733 - val_accuracy: 0.9875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMTmUoJWdWt-",
        "colab_type": "text"
      },
      "source": [
        "Our model started overfitting very early when the validation accuracy exceeded the training accuracy. The validation accuracy maxed out at 99.07% after a couple of epochs, while the training set kept on increasing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oTO-1swhjDfX"
      },
      "source": [
        "**Model 2: Dropout**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxXqD366eQGP",
        "colab_type": "text"
      },
      "source": [
        "To prevent overfitting we introduce regularization. First we introduce Dropout layers in the next model and see how we do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OcFDBmfczFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We put the model in a function we can call easily\n",
        "\n",
        "def MakeModel():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                     activation='relu',\n",
        "                     input_shape=input_shape))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "model = MakeModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o5ONw5KfT9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compose the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-iYwWpaferj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "9b92a983-b3fa-404b-a8b3-22c21aeeea5a"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    batch_size=32,\n",
        "                    epochs=10,\n",
        "                    verbose=2,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 - 7s - loss: 0.1900 - accuracy: 0.9420 - val_loss: 0.0444 - val_accuracy: 0.9855\n",
            "Epoch 2/10\n",
            "1875/1875 - 7s - loss: 0.0773 - accuracy: 0.9769 - val_loss: 0.0357 - val_accuracy: 0.9882\n",
            "Epoch 3/10\n",
            "1875/1875 - 7s - loss: 0.0582 - accuracy: 0.9823 - val_loss: 0.0330 - val_accuracy: 0.9894\n",
            "Epoch 4/10\n",
            "1875/1875 - 7s - loss: 0.0497 - accuracy: 0.9847 - val_loss: 0.0299 - val_accuracy: 0.9903\n",
            "Epoch 5/10\n",
            "1875/1875 - 7s - loss: 0.0414 - accuracy: 0.9869 - val_loss: 0.0264 - val_accuracy: 0.9906\n",
            "Epoch 6/10\n",
            "1875/1875 - 7s - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.0309 - val_accuracy: 0.9906\n",
            "Epoch 7/10\n",
            "1875/1875 - 7s - loss: 0.0297 - accuracy: 0.9902 - val_loss: 0.0284 - val_accuracy: 0.9912\n",
            "Epoch 8/10\n",
            "1875/1875 - 7s - loss: 0.0300 - accuracy: 0.9908 - val_loss: 0.0258 - val_accuracy: 0.9917\n",
            "Epoch 9/10\n",
            "1875/1875 - 7s - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0245 - val_accuracy: 0.9929\n",
            "Epoch 10/10\n",
            "1875/1875 - 7s - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0322 - val_accuracy: 0.9915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmeY7QWWgEqQ",
        "colab_type": "text"
      },
      "source": [
        "The model has greatly improved, with both the train and validation accuracy at 99.2%. But as we can see, there is a little bit of overfitting.\n",
        "\n",
        "We will try a different batch size of 1000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsGD4oMcim1g",
        "colab_type": "text"
      },
      "source": [
        "**Model 3: Batch Size**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXtui4QDfnQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "a70659cd-a00d-4c65-cc0d-6e27a09206df"
      },
      "source": [
        "model = MakeModel()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Batch size of 1000\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    batch_size=1000,\n",
        "                    epochs=10,\n",
        "                    verbose=2,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60/60 - 2s - loss: 0.5381 - accuracy: 0.8383 - val_loss: 0.1324 - val_accuracy: 0.9598\n",
            "Epoch 2/10\n",
            "60/60 - 2s - loss: 0.1531 - accuracy: 0.9550 - val_loss: 0.0650 - val_accuracy: 0.9797\n",
            "Epoch 3/10\n",
            "60/60 - 2s - loss: 0.1000 - accuracy: 0.9704 - val_loss: 0.0489 - val_accuracy: 0.9849\n",
            "Epoch 4/10\n",
            "60/60 - 2s - loss: 0.0771 - accuracy: 0.9774 - val_loss: 0.0394 - val_accuracy: 0.9858\n",
            "Epoch 5/10\n",
            "60/60 - 2s - loss: 0.0650 - accuracy: 0.9809 - val_loss: 0.0360 - val_accuracy: 0.9877\n",
            "Epoch 6/10\n",
            "60/60 - 2s - loss: 0.0554 - accuracy: 0.9833 - val_loss: 0.0352 - val_accuracy: 0.9882\n",
            "Epoch 7/10\n",
            "60/60 - 2s - loss: 0.0502 - accuracy: 0.9845 - val_loss: 0.0312 - val_accuracy: 0.9892\n",
            "Epoch 8/10\n",
            "60/60 - 2s - loss: 0.0456 - accuracy: 0.9864 - val_loss: 0.0310 - val_accuracy: 0.9904\n",
            "Epoch 9/10\n",
            "60/60 - 2s - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.0290 - val_accuracy: 0.9902\n",
            "Epoch 10/10\n",
            "60/60 - 2s - loss: 0.0370 - accuracy: 0.9889 - val_loss: 0.0294 - val_accuracy: 0.9897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaJ5F6dLhYYW",
        "colab_type": "text"
      },
      "source": [
        "While the validation accuracy does better than the training accuracy, the model did poorly compared to the last one. A large batch_size tends to get stuck in \"local minima\", therefore converging on the wrong solution.\n",
        "\n",
        "We will now try a different learning rate of 0.01 for our Adam optimizer instead of the default one of 0.001."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y05lOqctjkrt",
        "colab_type": "text"
      },
      "source": [
        "**Model 4: Learning Rate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnYhFYr_hFQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MakeModel()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Change learning rate\n",
        "adam = tensorflow.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evwXerOwj7sk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "cf593d01-fcdb-423b-abc2-816b843ae694"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    batch_size=32,\n",
        "                    epochs=10,\n",
        "                    verbose=2,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 - 7s - loss: 0.4345 - accuracy: 0.8666 - val_loss: 0.1295 - val_accuracy: 0.9593\n",
            "Epoch 2/10\n",
            "1875/1875 - 7s - loss: 0.2950 - accuracy: 0.9109 - val_loss: 0.1173 - val_accuracy: 0.9641\n",
            "Epoch 3/10\n",
            "1875/1875 - 7s - loss: 0.2845 - accuracy: 0.9146 - val_loss: 0.1241 - val_accuracy: 0.9635\n",
            "Epoch 4/10\n",
            "1875/1875 - 7s - loss: 0.2742 - accuracy: 0.9170 - val_loss: 0.1145 - val_accuracy: 0.9655\n",
            "Epoch 5/10\n",
            "1875/1875 - 7s - loss: 0.2625 - accuracy: 0.9212 - val_loss: 0.0997 - val_accuracy: 0.9693\n",
            "Epoch 6/10\n",
            "1875/1875 - 7s - loss: 0.2847 - accuracy: 0.9159 - val_loss: 0.1193 - val_accuracy: 0.9646\n",
            "Epoch 7/10\n",
            "1875/1875 - 7s - loss: 0.2665 - accuracy: 0.9199 - val_loss: 0.1187 - val_accuracy: 0.9645\n",
            "Epoch 8/10\n",
            "1875/1875 - 7s - loss: 0.2646 - accuracy: 0.9208 - val_loss: 0.1293 - val_accuracy: 0.9620\n",
            "Epoch 9/10\n",
            "1875/1875 - 7s - loss: 0.2598 - accuracy: 0.9224 - val_loss: 0.1332 - val_accuracy: 0.9627\n",
            "Epoch 10/10\n",
            "1875/1875 - 7s - loss: 0.2569 - accuracy: 0.9227 - val_loss: 0.1095 - val_accuracy: 0.9660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8uKOE73kz9p",
        "colab_type": "text"
      },
      "source": [
        "Not quite what we were aiming for, but at least we know that a higher learning rate is worse for this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5EYZ7OclJju",
        "colab_type": "text"
      },
      "source": [
        "**Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4093tSBtlUWX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   Dropout layers improved our model significantly by preventing overfitting\n",
        "*   A smaller batch size is better than a large batch size because it can easily wiggle out of a local minima to converge on the global minima.\n",
        "*   A smaller learning rate is better for our model.\n",
        "*   These hyperparameters can be tuned further to get the optimum result.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}